{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import io\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Transform, Format and Clean Data. \n",
    "\n",
    "# 2. Seperate into dimensions and facts\n",
    "\n",
    "# 3. Save the data into the warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON config file\n",
    "config_file_path = 'config.json'\n",
    "with open(config_file_path, 'r') as config_file:\n",
    "    config = json.load(config_file) \n",
    "\n",
    "# Azure connection string\n",
    "CONNECTION_STRING = config['AZURE_CONNECTION_STRING']\n",
    "blob_service_client = BlobServiceClient.from_connection_string(CONNECTION_STRING)\n",
    "\n",
    "# Database connection\n",
    "DATABASE = config['DW_CONNECTION_STRING']\n",
    "engine = create_engine(DATABASE)\n",
    "schema = config['DB_SCHEMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_list(container_name):\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_list = container_client.list_blobs()\n",
    "    return blob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_azure_blob_data(container_name, blob):\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_client = container_client.get_blob_client(blob.name)\n",
    "    stream = blob_client.download_blob()\n",
    "    blob_content = b\"\"\n",
    "    for chunk in stream.chunks():\n",
    "        blob_content += chunk\n",
    "    return blob_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    response = requests.get(url)\n",
    "    return io.BytesIO(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving the data from Azure Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppp_loan_data():\n",
    "    container_name = 'pppdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "    df_list = []  # Initialize df_list outside the loop\n",
    "\n",
    "    print(f\"Downloading data from {container_name} container\\n\")\n",
    "    for blob in blob_list:\n",
    "        print(f\"Downloading:\\t{blob.name}\")\n",
    "        blob_data = get_azure_blob_data(container_name, blob)\n",
    "        print(f\"Downloaded {blob.name} successfully\\n\")\n",
    "        data = io.BytesIO(blob_data)\n",
    "        print(f\"Reading:\\t{blob.name}\")\n",
    "        df_chunks = pd.read_csv(data, chunksize=100000)  # Adjust the chunksize as per your memory capacity\n",
    "        for chunk in df_chunks:\n",
    "            df_list.append(chunk)\n",
    "        print(f\"Read {blob.name} successfully\\n\\n\")\n",
    "    \n",
    "    if df_list:  # Check if df_list is not empty\n",
    "        df = pd.concat(df_list)\n",
    "        print(f\"PPP consolidated successfully\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data downloaded.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_ppp_loan_data():\\n    container_name = \\'pppdata\\'\\n    blob_list = get_blob_list(container_name)\\n    \\n    for blob in blob_list:\\n        if \"public_150k_plus\" in blob.name:\\n            print(f\"Downloading {blob.name}\")\\n            blob_data = get_azure_blob_data(container_name, blob)\\n            print(f\"Downloaded {blob.name} successfully\")\\n            data = io.BytesIO(blob_data)\\n            print(f\"Reading {blob.name}\")\\n            df_chunks = pd.read_csv(data, chunksize=100000)  # Adjust the chunksize as per your memory capacity\\n            df_list = []\\n            for chunk in df_chunks:\\n                df_list.append(chunk)\\n            df = pd.concat(df_list)\\n            return df'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing only one file\n",
    "\"\"\"def get_ppp_loan_data():\n",
    "    container_name = 'pppdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "    \n",
    "    for blob in blob_list:\n",
    "        if \"public_150k_plus\" in blob.name:\n",
    "            print(f\"Downloading {blob.name}\")\n",
    "            blob_data = get_azure_blob_data(container_name, blob)\n",
    "            print(f\"Downloaded {blob.name} successfully\")\n",
    "            data = io.BytesIO(blob_data)\n",
    "            print(f\"Reading {blob.name}\")\n",
    "            df_chunks = pd.read_csv(data, chunksize=100000)  # Adjust the chunksize as per your memory capacity\n",
    "            df_list = []\n",
    "            for chunk in df_chunks:\n",
    "                df_list.append(chunk)\n",
    "            df = pd.concat(df_list)\n",
    "            return df\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naics_data():\n",
    "    container_name = 'naicsdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "\n",
    "    for blob in blob_list:\n",
    "        blob_data = get_azure_blob_data(container_name, blob)\n",
    "        data = io.BytesIO(blob_data)\n",
    "        df = pd.read_csv(data)\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdp_data():\n",
    "    container_name = 'gdpdata'\n",
    "    blob_list = get_blob_list(container_name)\n",
    "\n",
    "    for blob in blob_list:\n",
    "        blob_data = get_azure_blob_data(container_name, blob)\n",
    "        data = io.BytesIO(blob_data)\n",
    "        df = pd.read_csv(data)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformating, and Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_naics_data():\n",
    "    df_naics = get_naics_data()\n",
    "    df_naics.rename(columns={\n",
    "        'Code': 'naics_code',\n",
    "        'Title': 'naics_title',\n",
    "        'Description': 'description'\n",
    "    }, inplace=True)\n",
    "    # Remove all the rows where naics_code is not a number\n",
    "    # The naics_code column has some generic values like \"31-33\" which are not valid NAICS codes\n",
    "    df_naics = df_naics[df_naics['naics_code'].str.isnumeric()]\n",
    "\n",
    "    # Remove T from naics_title\n",
    "    df_naics['naics_title'] = df_naics['naics_title'].str.replace('T', '')\n",
    "\n",
    "    # Convert the data types\n",
    "    df_naics['naics_code'] = df_naics['naics_code'].astype(int)\n",
    "    df_naics['naics_title'] = df_naics['naics_title'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_naics['description'] = df_naics['description'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    \n",
    "    return df_naics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_gdp_data():\n",
    "    df_gdp  = get_gdp_data()\n",
    "    #Drop all the records where 2017, 2018, 2019, 2020, 2021, 2022 = \"(NA)\" \n",
    "    df_gdp = df_gdp[df_gdp['2017'] != \"(NA)\"]\n",
    "    df_gdp = df_gdp[df_gdp['2020'] != \"(NA)\"]\n",
    "\n",
    "    # Pivot the data in GDP data\n",
    "    selected_columns = ['GeoFIPS', 'GeoName', 'Region', 'Description', '2017', '2018', '2019', '2020', '2021', '2022']\n",
    "    df_gdp = df_gdp[selected_columns]\n",
    "    pivot_data = df_gdp.melt(id_vars=[\"GeoFIPS\", \"GeoName\", \"Region\", \"Description\"],\n",
    "                                    value_vars=[\"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\"],\n",
    "                                    var_name=\"date_id\",\n",
    "                                    value_name=\"Value\")\n",
    "    pivot_data = pivot_data.pivot_table(index=[\"GeoFIPS\", \"GeoName\", \"Region\", \"date_id\"], columns=\"Description\", values=\"Value\", aggfunc='first').reset_index()\n",
    "    pivot_data = pivot_data.sort_values(by=[\"GeoFIPS\", \"date_id\"])\n",
    "    pivot_data.rename(columns={\n",
    "        \"Chain-type quantity indexes for real GDP \": \"chain_type_index_gdp\",\n",
    "        \"Current-dollar GDP (thousands of current dollars) \": \"current_dollar_gdp\",\n",
    "        \"Real GDP (thousands of chained 2017 dollars) \": \"real_gdp\",\n",
    "        \"GeoFIPS\": \"geofips\",\n",
    "        \"GeoName\": \"geo_name\",\n",
    "        \"Description\": \"Index\",\n",
    "        \"date_id\": \"year_id\",\n",
    "        \"Region\": \"region\"\n",
    "    }, inplace=True)\n",
    "    pivot_data['facts_gdp_id'] = range(1, len(pivot_data) + 1)\n",
    "    final_data = pivot_data.drop(columns='Description', errors='ignore')\n",
    "    final_data = pivot_data[['facts_gdp_id', 'geofips', 'geo_name', 'region', 'year_id', 'chain_type_index_gdp',\n",
    "                         'current_dollar_gdp', 'real_gdp']]\n",
    "    df_gdp = final_data\n",
    "\n",
    "    # Remove the quation marks from geofips\n",
    "    df_gdp['geofips'] = df_gdp['geofips'].str.replace('\"', '')\n",
    "    \n",
    "    # Change the YearID to match the format in the Date Dimension\n",
    "    df_gdp['year_id'] = pd.to_datetime(df_gdp['year_id'], format='%Y').dt.strftime('%Y%m%d%H')\n",
    "    \n",
    "    # Change the data types of the columns\n",
    "    df_gdp['year_id'] = df_gdp['year_id'].astype(int)\n",
    "    df_gdp['geofips'] = df_gdp['geofips'].astype(int)\n",
    "    df_gdp['geo_name'] = df_gdp['geo_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_gdp['region'] = df_gdp['region'].astype(pd.StringDtype(\"pyarrow\"))    \n",
    "    df_gdp['chain_type_index_gdp'] = df_gdp['chain_type_index_gdp'].astype(float)\n",
    "    df_gdp['current_dollar_gdp'] = df_gdp['current_dollar_gdp'].astype(float)\n",
    "    df_gdp['real_gdp'] = df_gdp['real_gdp'].astype(float)\n",
    "\n",
    "\n",
    "    return df_gdp\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_ppp_loan_data():\n",
    "    df_ppp = get_ppp_loan_data()\n",
    "\n",
    "\n",
    "    # Delete the columns that are not required\n",
    "    df_ppp.drop(columns=[\n",
    "        'UTILITIES_PROCEED',\n",
    "        'PAYROLL_PROCEED',\n",
    "        'MORTGAGE_INTEREST_PROCEED',\n",
    "        'RENT_PROCEED',\n",
    "        'REFINANCE_EIDL_PROCEED',\n",
    "        'HEALTH_CARE_PROCEED',\n",
    "        'DEBT_INTEREST_PROCEED',\n",
    "        'RuralUrbanIndicator',\n",
    "        'HubzoneIndicator',\n",
    "        'LMIIndicator',\n",
    "        'ProjectCity',\n",
    "        'ProjectZip',\n",
    "        'CD'\n",
    "    ], inplace=True)\n",
    "    # Rename the columns to match the SQL table\n",
    "    df_ppp.rename(columns={\n",
    "        'LoanNumber': 'loan_number',\n",
    "        'DateApproved': 'date_approved_id',\n",
    "        'SBAOfficeCode': 'sba_office_code',\n",
    "        'ProcessingMethod': 'processing_method',\n",
    "        'BorrowerName': 'borrower_name',\n",
    "        'BorrowerAddress': 'borrower_address',\n",
    "        'BorrowerCity': 'borrower_city',\n",
    "        'BorrowerState': 'borrower_state',\n",
    "        'BorrowerZip': 'borrower_zip',\n",
    "        'LoanStatusDate': 'loan_status_date_id',\n",
    "        'LoanStatus': 'loan_status',\n",
    "        'Term': 'term_month',\n",
    "        'SBAGuarantyPercentage': 'sba_guaranty_percentage',\n",
    "        'InitialApprovalAmount': 'initial_approval_amount',\n",
    "        'CurrentApprovalAmount': 'current_approval_amount',\n",
    "        'UndisbursedAmount': 'undisbursed_amount',\n",
    "        'FranchiseName': 'franchise_name',\n",
    "        'ServicingLenderLocationID': 'servicing_lender_location_id',\n",
    "        'ServicingLenderName': 'servicing_lender_name',\n",
    "        'ServicingLenderAddress': 'servicing_lender_address',\n",
    "        'ServicingLenderCity': 'servicing_lender_city',\n",
    "        'ServicingLenderState': 'servicing_lender_state',\n",
    "        'ServicingLenderZip': 'servicing_lender_zip',\n",
    "        'BusinessAgeDescription': 'business_age_description',\n",
    "        'ProjectState': 'project_state',\n",
    "        'ProjectCountyName': 'project_county_name',\n",
    "        'Race': 'race',\n",
    "        'Ethnicity': 'ethnicity',\n",
    "        'Gender': 'gender',\n",
    "        'BusinessType': 'business_type',\n",
    "        'OriginatingLenderLocationID': 'originating_lender_location_id',\n",
    "        'OriginatingLender': 'originating_lender',\n",
    "        'OriginatingLenderCity': 'originating_lender_city',\n",
    "        'OriginatingLenderState': 'originating_lender_state',\n",
    "        'Veteran': 'veteran',\n",
    "        'NonProfit': 'nonprofit',\n",
    "        'ForgivenessAmount': 'forgiveness_amount',\n",
    "        'ForgivenessDate': 'forgiveness_date_id',\n",
    "        'JobsReported': 'jobs_reported',\n",
    "        'NAICSCode': 'naics_code'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Droping all the empty rows\n",
    "    # Drop all the rows where Borrower State is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['borrower_state'])\n",
    "\n",
    "    # Drop all the rows where naics_code is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['naics_code'])\n",
    "\n",
    "    # Drop all the rows where dates are empty\n",
    "    df_ppp = df_ppp.dropna(subset=['date_approved_id', 'loan_status_date_id', 'forgiveness_date_id'])\n",
    "\n",
    "    # Drop all the rows where jobs reported is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['jobs_reported'])\n",
    "\n",
    "    # Drop all the rows where business type is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['business_type'])\n",
    "\n",
    "    # Drop all the rows where business age description is empty\n",
    "    df_ppp = df_ppp.dropna(subset=['business_age_description'])\n",
    "    # or where the value is Unanswered\n",
    "    df_ppp = df_ppp[df_ppp['business_age_description'] != 'Unanswered']\n",
    "\n",
    "    \n",
    "\n",
    "    # Change the Date columns to match the format in the Date Dimension\n",
    "    df_ppp['forgiveness_date_id'] = pd.to_datetime(df_ppp['forgiveness_date_id']).dt.strftime('%Y%m%d%H')\n",
    "    df_ppp['date_approved_id'] = pd.to_datetime(df_ppp['date_approved_id']).dt.strftime('%Y%m%d%H')\n",
    "    df_ppp['loan_status_date_id'] = pd.to_datetime(df_ppp['loan_status_date_id']).dt.strftime('%Y%m%d%H')\n",
    "    \n",
    "    # Change nonprofit to boolean\n",
    "    df_ppp['nonprofit'] = df_ppp['nonprofit'].map({'Y': True})\n",
    "    df_ppp['nonprofit'] = df_ppp['nonprofit'].fillna(False)\n",
    "\n",
    "    # Change veteran to boolean\n",
    "    df_ppp['veteran'] = df_ppp['veteran'].map({'veteran': True, 'Non-veteran': False, 'Unanswered':None})\n",
    "\n",
    "    # Sentence case the string columns\n",
    "    df_ppp['borrower_address'] = df_ppp['borrower_address'].str.title()\n",
    "    df_ppp['borrower_city'] = df_ppp['borrower_city'].str.title()\n",
    "    df_ppp['originating_lender_city'] = df_ppp['originating_lender_city'].str.title()\n",
    "    df_ppp['servicing_lender_city'] = df_ppp['servicing_lender_city'].str.title()\n",
    "    df_ppp['project_county_name'] = df_ppp['project_county_name'].str.title()\n",
    "    \n",
    "    #df_ppp['loan_number'] = df_ppp['loan_number'].astype(int)\n",
    "    df_ppp['date_approved_id'] = df_ppp['date_approved_id'].astype(int)\n",
    "    df_ppp['sba_office_code'] = df_ppp['sba_office_code'].astype(int)\n",
    "    df_ppp['processing_method'] = df_ppp['processing_method'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['borrower_name'] = df_ppp['borrower_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['borrower_address'] = df_ppp['borrower_address'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['borrower_city'] = df_ppp['borrower_city'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['borrower_state'] = df_ppp['borrower_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['borrower_zip'] = df_ppp['borrower_zip'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['loan_status_date_id'] = df_ppp['loan_status_date_id'].astype(int)\n",
    "    df_ppp['loan_status'] = df_ppp['loan_status'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['term_month'] = df_ppp['term_month'].astype(int)\n",
    "    df_ppp['sba_guaranty_percentage'] = df_ppp['sba_guaranty_percentage'].astype(float)\n",
    "    df_ppp['initial_approval_amount'] = df_ppp['initial_approval_amount'].astype(float)\n",
    "    df_ppp['current_approval_amount'] = df_ppp['current_approval_amount'].astype(float)\n",
    "    df_ppp['undisbursed_amount'] = df_ppp['undisbursed_amount'].astype(float)\n",
    "    df_ppp['franchise_name'] = df_ppp['franchise_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['servicing_lender_location_id'] = df_ppp['servicing_lender_location_id'].astype(int)\n",
    "    df_ppp['servicing_lender_name'] = df_ppp['servicing_lender_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['servicing_lender_address'] = df_ppp['servicing_lender_address'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['servicing_lender_city'] = df_ppp['servicing_lender_city'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['servicing_lender_state'] = df_ppp['servicing_lender_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['servicing_lender_zip'] = df_ppp['servicing_lender_zip'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['business_age_description'] = df_ppp['business_age_description'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['project_state'] = df_ppp['project_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['project_county_name'] = df_ppp['project_county_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['race'] = df_ppp['race'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['ethnicity'] = df_ppp['ethnicity'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['gender'] = df_ppp['gender'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['business_type'] = df_ppp['business_type'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['originating_lender_location_id'] = df_ppp['originating_lender_location_id'].astype(int)\n",
    "    df_ppp['originating_lender'] = df_ppp['originating_lender'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['originating_lender_city'] = df_ppp['originating_lender_city'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['originating_lender_state'] = df_ppp['originating_lender_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "    df_ppp['veteran'] = df_ppp['veteran'].astype(bool)\n",
    "    df_ppp['nonprofit'] = df_ppp['nonprofit'].astype(bool)\n",
    "    df_ppp['forgiveness_amount'] = df_ppp['forgiveness_amount'].astype(float)\n",
    "    df_ppp['forgiveness_date_id'] = df_ppp['forgiveness_date_id'].astype(int)\n",
    "    df_ppp['jobs_reported'] = df_ppp['jobs_reported'].astype(int)\n",
    "    df_ppp['naics_code'] = df_ppp['naics_code'].astype(int)\n",
    "\n",
    "    # Create a FACTS_PPP_ID \n",
    "    df_ppp['facts_ppp_id'] = range(1, len(df_ppp) + 1)\n",
    "\n",
    "    return df_ppp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Dimensions and Facts Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAICS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naics_code</th>\n",
       "      <th>naics_title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Agriculture, Forestry, Fishing and Hunting</td>\n",
       "      <td>The Sector as a Whole\n",
       "\n",
       "The Agriculture, Forest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "      <td>Crop Production</td>\n",
       "      <td>Industries in the Crop Production subsector gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1111</td>\n",
       "      <td>Oilseed and Grain Farming</td>\n",
       "      <td>This industry group comprises establishments p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11111</td>\n",
       "      <td>Soybean Farming</td>\n",
       "      <td>See industry description for 111110.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111110</td>\n",
       "      <td>Soybean Farming</td>\n",
       "      <td>This industry comprises establishments primari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   naics_code                                 naics_title  \\\n",
       "0          11  Agriculture, Forestry, Fishing and Hunting   \n",
       "1         111                             Crop Production   \n",
       "2        1111                   Oilseed and Grain Farming   \n",
       "3       11111                             Soybean Farming   \n",
       "4      111110                             Soybean Farming   \n",
       "\n",
       "                                         description  \n",
       "0  The Sector as a Whole\n",
       "\n",
       "The Agriculture, Forest...  \n",
       "1  Industries in the Crop Production subsector gr...  \n",
       "2  This industry group comprises establishments p...  \n",
       "3               See industry description for 111110.  \n",
       "4  This industry comprises establishments primari...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_naics_data = reformat_naics_data()\n",
    "# Create the dimensions\n",
    "dim_naics = clean_naics_data # Completed\n",
    "\n",
    "# Reset the index\n",
    "dim_naics.reset_index(drop=True, inplace=True)\n",
    "dim_naics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dim_naics data into the database...\n",
      "dim_naics data loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data into the database\n",
    "print(\"Loading dim_naics data into the database...\")\n",
    "#dim_naics.to_sql('dim_naics', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_naics data loaded successfully\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Dimension\n",
    "Start date: 2017-01-01 00:00:00 \n",
    "\n",
    "2017 is the minimum year in the GDP data\n",
    "\n",
    "End date: 2023-10-1 00:00:00 \n",
    "\n",
    "October 2023 is the maximum date in the PPP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>date_iso_format</th>\n",
       "      <th>year_number</th>\n",
       "      <th>quarter_number</th>\n",
       "      <th>month_number</th>\n",
       "      <th>day_number</th>\n",
       "      <th>hour_number</th>\n",
       "      <th>month_name</th>\n",
       "      <th>day_name</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>week_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017010100</td>\n",
       "      <td>2017-01-01T00:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017010101</td>\n",
       "      <td>2017-01-01T01:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017010102</td>\n",
       "      <td>2017-01-01T02:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017010103</td>\n",
       "      <td>2017-01-01T03:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017010104</td>\n",
       "      <td>2017-01-01T04:00:00</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>January</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_id      date_iso_format  year_number  quarter_number  month_number  \\\n",
       "0  2017010100  2017-01-01T00:00:00         2017               1             1   \n",
       "1  2017010101  2017-01-01T01:00:00         2017               1             1   \n",
       "2  2017010102  2017-01-01T02:00:00         2017               1             1   \n",
       "3  2017010103  2017-01-01T03:00:00         2017               1             1   \n",
       "4  2017010104  2017-01-01T04:00:00         2017               1             1   \n",
       "\n",
       "   day_number  hour_number month_name day_name week_of_year  week_of_month  \n",
       "0           1            0    January   Sunday           01              1  \n",
       "1           1            1    January   Sunday           01              1  \n",
       "2           1            2    January   Sunday           01              1  \n",
       "3           1            3    January   Sunday           01              1  \n",
       "4           1            4    January   Sunday           01              1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def week_of_month(dt):\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day = dt.day\n",
    "\n",
    "    cal = calendar.monthcalendar(year, month)\n",
    "    week_number = (day - 1) // 7 + 1\n",
    "    return week_number\n",
    "\n",
    "start_date = pd.to_datetime('2017-01-01 00:00:00') #2017 is the start date in the GDP data\n",
    "end_date = pd.to_datetime('2023-10-01 00:00:00') # 2023 is the end date in the PPP data\n",
    "\n",
    "# Create a DataFrame for the date dimension\n",
    "dim_date = pd.DataFrame({'date': pd.date_range(start_date, end_date, freq='H')})\n",
    "\n",
    "# Extract attributes\n",
    "dim_date['year_number'] = dim_date['date'].dt.year\n",
    "dim_date['quarter_number'] = dim_date['date'].dt.quarter #quarter_number\n",
    "dim_date['month_number'] = dim_date['date'].dt.month\n",
    "dim_date['month_name'] = dim_date['date'].dt.strftime('%B')\n",
    "dim_date['day_number'] = dim_date['date'].dt.day #day_number\n",
    "dim_date['day_name'] = dim_date['date'].dt.strftime('%A') #day_name\n",
    "dim_date['hour_number'] = dim_date['date'].dt.hour #hour_number\n",
    "dim_date['date_iso_format'] = dim_date['date'].apply(lambda x: x.isoformat())\n",
    "dim_date['date_id'] = dim_date['date'].dt.strftime('%Y%m%d%H')\n",
    "\n",
    "# Add week of the month and week of the year\n",
    "dim_date['week_of_month'] = dim_date['date'].apply(week_of_month) #week_of_month\n",
    "dim_date['week_of_year'] = dim_date['date'].dt.strftime('%U') #week_of_year\n",
    "\n",
    "new_order = ['date_id', 'date_iso_format','year_number','quarter_number','month_number','day_number','hour_number','month_name','day_name','week_of_year','week_of_month']\n",
    "dim_date = dim_date[new_order]\n",
    "\n",
    "dim_date.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dim_date data into the database...\n",
      "dim_date data loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dim_date data into the database...\")\n",
    "#dim_date.to_sql('dim_date', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_date data loaded successfully\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3758441856.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  dim_geography['geo_name'] = dim_geography['geo_name'].str.replace('*', '')\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3758441856.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' (Independent City)', '')\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3758441856.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(r'(.+),.+,', r'\\1,')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Description</th>\n",
       "      <th>geofips</th>\n",
       "      <th>geo_name</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga, AL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Baldwin, AL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Barbour, AL</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2275</td>\n",
       "      <td>Wrangell, AK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2282</td>\n",
       "      <td>Yakutat, AK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2290</td>\n",
       "      <td>Yukon-Koyukuk, AK</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4000</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4001</td>\n",
       "      <td>Apache, AZ</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Description  geofips           geo_name region\n",
       "0                  0      United States       \n",
       "1               1000            Alabama      5\n",
       "2               1001        Autauga, AL      5\n",
       "3               1003        Baldwin, AL      5\n",
       "4               1005        Barbour, AL      5\n",
       "..               ...                ...    ...\n",
       "95              2275       Wrangell, AK      8\n",
       "96              2282        Yakutat, AK      8\n",
       "97              2290  Yukon-Koyukuk, AK      8\n",
       "98              4000            Arizona      6\n",
       "99              4001         Apache, AZ      6\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_gdp_data = reformat_gdp_data()\n",
    "dim_geography = clean_gdp_data[['geofips', 'geo_name', 'region']].drop_duplicates()\n",
    "dim_geography = dim_geography.reset_index(drop=True)\n",
    "\n",
    "# Remove the * from the geo_name\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace('*', '')\n",
    "\n",
    "#Remove the County, Parish, Borough, Census Area, Municipality, City and Borough, (Independent City) from the geo_name\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' City and Borough', '')\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' Borough', '')\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' Census Area', '')\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' Municipality', '')\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(' (Independent City)', '')\n",
    "\n",
    "# Special cases. Ex: Augusta, Staunton + Waynesboro, VA -> Augusta, VA\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].str.replace(r'(.+),.+,', r'\\1,')\n",
    "\n",
    "\n",
    "dim_geography.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Description</th>\n",
       "      <th>geofips</th>\n",
       "      <th>geo_name</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>15000</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>15001</td>\n",
       "      <td>Hawaii, HI</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>15003</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>15007</td>\n",
       "      <td>Kauai, HI</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>15901</td>\n",
       "      <td>Maui + Kalawao, HI</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>16000</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Description  geofips            geo_name region\n",
       "557            15000              Hawaii      8\n",
       "558            15001          Hawaii, HI      8\n",
       "559            15003        Honolulu, HI      8\n",
       "560            15007           Kauai, HI      8\n",
       "561            15901  Maui + Kalawao, HI      8\n",
       "562            16000               Idaho      7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show me the data for geofips 15000 to 16000\n",
    "dim_geography[(dim_geography['geofips'] >= 15000) & (dim_geography['geofips'] <= 16000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Description</th>\n",
       "      <th>geofips</th>\n",
       "      <th>geo_name</th>\n",
       "      <th>region</th>\n",
       "      <th>project_state</th>\n",
       "      <th>project_county_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td></td>\n",
       "      <td>All States</td>\n",
       "      <td>All Counties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>All Counties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>Autauga, AL</td>\n",
       "      <td>5</td>\n",
       "      <td>AL</td>\n",
       "      <td>Autauga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Baldwin, AL</td>\n",
       "      <td>5</td>\n",
       "      <td>AL</td>\n",
       "      <td>Baldwin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Barbour, AL</td>\n",
       "      <td>5</td>\n",
       "      <td>AL</td>\n",
       "      <td>Barbour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2275</td>\n",
       "      <td>Wrangell, AK</td>\n",
       "      <td>8</td>\n",
       "      <td>AK</td>\n",
       "      <td>Wrangell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2282</td>\n",
       "      <td>Yakutat, AK</td>\n",
       "      <td>8</td>\n",
       "      <td>AK</td>\n",
       "      <td>Yakutat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2290</td>\n",
       "      <td>Yukon-Koyukuk, AK</td>\n",
       "      <td>8</td>\n",
       "      <td>AK</td>\n",
       "      <td>Yukon-Koyukuk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4000</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>All Counties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4001</td>\n",
       "      <td>Apache, AZ</td>\n",
       "      <td>6</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Apache</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Description  geofips           geo_name region project_state  \\\n",
       "0                  0      United States           All States   \n",
       "1               1000            Alabama      5       Alabama   \n",
       "2               1001        Autauga, AL      5            AL   \n",
       "3               1003        Baldwin, AL      5            AL   \n",
       "4               1005        Barbour, AL      5            AL   \n",
       "..               ...                ...    ...           ...   \n",
       "95              2275       Wrangell, AK      8            AK   \n",
       "96              2282        Yakutat, AK      8            AK   \n",
       "97              2290  Yukon-Koyukuk, AK      8            AK   \n",
       "98              4000            Arizona      6       Arizona   \n",
       "99              4001         Apache, AZ      6            AZ   \n",
       "\n",
       "Description project_county_name  \n",
       "0                  All Counties  \n",
       "1                  All Counties  \n",
       "2                       Autauga  \n",
       "3                       Baldwin  \n",
       "4                       Barbour  \n",
       "..                          ...  \n",
       "95                     Wrangell  \n",
       "96                      Yakutat  \n",
       "97                Yukon-Koyukuk  \n",
       "98                 All Counties  \n",
       "99                       Apache  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the geo_name into project_state and project_county_name\n",
    "dim_geography['project_state'] = dim_geography['geo_name'].str.split(',').str[1].str.strip()\n",
    "dim_geography['project_county_name'] = dim_geography['geo_name'].str.split(',').str[0].str.strip()\n",
    "\n",
    "# Temporarily set geofips to string\n",
    "dim_geography['geofips'] = dim_geography['geofips'].astype(str)\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].astype(str)\n",
    "\n",
    "# Set the project_state and project_county_name for the United States\n",
    "dim_geography.loc[dim_geography['geofips'] == '0', 'project_state'] = 'All States'\n",
    "dim_geography.loc[dim_geography['geofips'] == '0', 'project_county_name'] = 'All Counties'\n",
    "\n",
    "# Set the project_state and project_county_name for the States\n",
    "dim_geography.loc[dim_geography['geofips'].str.endswith('000'), 'project_state'] = dim_geography['geo_name']\n",
    "dim_geography.loc[dim_geography['geofips'].str.endswith('000'), 'project_county_name'] = 'All Counties'\n",
    "\n",
    "# Set the data types\n",
    "dim_geography['geofips'] = dim_geography['geofips'].astype(int)\n",
    "dim_geography['geo_name'] = dim_geography['geo_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "dim_geography['region'] = dim_geography['region'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "dim_geography['project_state'] = dim_geography['project_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "dim_geography['project_county_name'] = dim_geography['project_county_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "dim_geography.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Description</th>\n",
       "      <th>facts_gdp_id</th>\n",
       "      <th>geofips</th>\n",
       "      <th>year_id</th>\n",
       "      <th>chain_type_index_gdp</th>\n",
       "      <th>current_dollar_gdp</th>\n",
       "      <th>real_gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017010100</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1.961210e+10</td>\n",
       "      <td>1.961210e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2018010100</td>\n",
       "      <td>102.967</td>\n",
       "      <td>2.065652e+10</td>\n",
       "      <td>2.019390e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2019010100</td>\n",
       "      <td>105.507</td>\n",
       "      <td>2.152140e+10</td>\n",
       "      <td>2.069209e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2020010100</td>\n",
       "      <td>103.171</td>\n",
       "      <td>2.132295e+10</td>\n",
       "      <td>2.023407e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2021010100</td>\n",
       "      <td>109.156</td>\n",
       "      <td>2.359403e+10</td>\n",
       "      <td>2.140769e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Description  facts_gdp_id  geofips     year_id  chain_type_index_gdp  \\\n",
       "0                       1        0  2017010100               100.000   \n",
       "1                       2        0  2018010100               102.967   \n",
       "2                       3        0  2019010100               105.507   \n",
       "3                       4        0  2020010100               103.171   \n",
       "4                       5        0  2021010100               109.156   \n",
       "\n",
       "Description  current_dollar_gdp      real_gdp  \n",
       "0                  1.961210e+10  1.961210e+10  \n",
       "1                  2.065652e+10  2.019390e+10  \n",
       "2                  2.152140e+10  2.069209e+10  \n",
       "3                  2.132295e+10  2.023407e+10  \n",
       "4                  2.359403e+10  2.140769e+10  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Fact Table\n",
    "facts_gdp = clean_gdp_data[['facts_gdp_id', 'year_id', 'real_gdp', 'chain_type_index_gdp', 'current_dollar_gdp', 'geofips']]\n",
    "# Reset the index\n",
    "facts_gdp.reset_index(drop=True, inplace=True)\n",
    "# Re order the columns\n",
    "facts_gdp = facts_gdp[['facts_gdp_id', 'geofips', 'year_id', 'chain_type_index_gdp', 'current_dollar_gdp', 'real_gdp']]\n",
    "facts_gdp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dim_geography data into the database...\n",
      "dim_geography data loaded successfully\n",
      "\n",
      "Loading facts_gdp data into the database...\n",
      "facts_gdp data loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data into the database\n",
    "print(\"Loading dim_geography data into the database...\")\n",
    "#dim_geography.to_sql('dim_geography', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_geography data loaded successfully\\n\")\n",
    "\n",
    "print(\"Loading facts_gdp data into the database...\")\n",
    "#facts_gdp.to_sql('facts_gdp', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"facts_gdp data loaded successfully\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from pppdata container\n",
      "\n",
      "Downloading:\tpublic_150k_plus_230930.csv\n",
      "Downloaded public_150k_plus_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_150k_plus_230930.csv\n",
      "Read public_150k_plus_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_10_230930.csv\n",
      "Downloaded public_up_to_150k_10_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_10_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_10_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_11_230930.csv\n",
      "Downloaded public_up_to_150k_11_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_11_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3311423452.py:14: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_11_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_12_230930.csv\n",
      "Downloaded public_up_to_150k_12_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_12_230930.csv\n",
      "Read public_up_to_150k_12_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_1_230930.csv\n",
      "Downloaded public_up_to_150k_1_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_1_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_1_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_2_230930.csv\n",
      "Downloaded public_up_to_150k_2_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_2_230930.csv\n",
      "Read public_up_to_150k_2_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_3_230930.csv\n",
      "Downloaded public_up_to_150k_3_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_3_230930.csv\n",
      "Read public_up_to_150k_3_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_4_230930.csv\n",
      "Downloaded public_up_to_150k_4_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_4_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3311423452.py:14: DtypeWarning: Columns (16,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3311423452.py:14: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_4_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_5_230930.csv\n",
      "Downloaded public_up_to_150k_5_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_5_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3311423452.py:14: DtypeWarning: Columns (16,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n",
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_5_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_6_230930.csv\n",
      "Downloaded public_up_to_150k_6_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_6_230930.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/rykg94fx3sx8n33hc83qjkmw0000gn/T/ipykernel_65103/3311423452.py:14: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in df_chunks:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read public_up_to_150k_6_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_7_230930.csv\n",
      "Downloaded public_up_to_150k_7_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_7_230930.csv\n",
      "Read public_up_to_150k_7_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_8_230930.csv\n",
      "Downloaded public_up_to_150k_8_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_8_230930.csv\n",
      "Read public_up_to_150k_8_230930.csv successfully\n",
      "\n",
      "\n",
      "Downloading:\tpublic_up_to_150k_9_230930.csv\n",
      "Downloaded public_up_to_150k_9_230930.csv successfully\n",
      "\n",
      "Reading:\tpublic_up_to_150k_9_230930.csv\n",
      "Read public_up_to_150k_9_230930.csv successfully\n",
      "\n",
      "\n",
      "PPP consolidated successfully\n"
     ]
    }
   ],
   "source": [
    "clean_ppp_data = reformat_ppp_loan_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status_id</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paid in Full</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Charged Off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_status_id   loan_status\n",
       "0               1  Paid in Full\n",
       "1               2   Charged Off"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_loan_status = pd.DataFrame({'loan_status': ['Paid in Full', 'Charged Off']})\n",
    "dim_loan_status[\"loan_status_id\"] = range(1, len(dim_loan_status) + 1)\n",
    "# Change the column order\n",
    "dim_loan_status = dim_loan_status[['loan_status_id', 'loan_status']]\n",
    "# Reset the index\n",
    "dim_loan_status = dim_loan_status.reset_index(drop=True)\n",
    "# Merge the clean_ppp_data with the dim_loan_status to get the loan_status_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_loan_status[['loan_status', 'loan_status_id']], on='loan_status', how='left', suffixes=('', '_dim_loan_status'))\n",
    "dim_loan_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processing_method_id</th>\n",
       "      <th>processing_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PPP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   processing_method_id processing_method\n",
       "0                     1               PPP\n",
       "1                     2               PPS"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_processing_method = pd.DataFrame({'processing_method': ['PPP', 'PPS']})\n",
    "dim_processing_method[\"processing_method_id\"] = range(1, len(dim_processing_method) + 1)\n",
    "# Change the column order\n",
    "dim_processing_method = dim_processing_method[['processing_method_id', 'processing_method']]\n",
    "# Reset the index\n",
    "dim_processing_method = dim_processing_method.reset_index(drop=True)\n",
    "# Merge the clean_ppp_data with the dim_processing_method to get the processing_method_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_processing_method[['processing_method', 'processing_method_id']], on='processing_method', how='left', suffixes=('', '_dim_processing_method'))\n",
    "dim_processing_method.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dim_loan_status data into the database...\n",
      "dim_loan_status data loaded successfully\n",
      "\n",
      "Loading dim_processing_method data into the database...\n",
      "dim_processing_method data loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dim_loan_status data into the database...\")\n",
    "#dim_loan_status.to_sql('dim_loan_status', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_loan_status data loaded successfully\\n\")\n",
    "\n",
    "print(\"Loading dim_processing_method data into the database...\")\n",
    "#dim_processing_method.to_sql('dim_processing_method', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_processing_method data loaded successfully\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_type_id</th>\n",
       "      <th>business_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Limited  Liability Company(LLC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Non-Profit Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>501(c)3 – Non Profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cooperative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business_type_id                    business_type\n",
       "0                 1  Limited  Liability Company(LLC)\n",
       "1                 2          Non-Profit Organization\n",
       "2                 3             501(c)3 – Non Profit\n",
       "3                 4                      Corporation\n",
       "4                 5                      Cooperative"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_business_type = clean_ppp_data[['business_type']].drop_duplicates()\n",
    "dim_business_type[\"business_type_id\"] = range(1, len(dim_business_type) + 1)\n",
    "\n",
    "# Change the column order\n",
    "dim_business_type = dim_business_type[['business_type_id', 'business_type']]\n",
    "\n",
    "# Reset the index\n",
    "dim_business_type = dim_business_type.reset_index(drop=True)\n",
    "\n",
    "# Merge the clean_ppp_data with the dim_business_type to get the business_type_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_business_type[['business_type', 'business_type_id']], on='business_type', how='left', suffixes=('', '_dim_business_type'))\n",
    "dim_business_type.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sba_office_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sba_office_code\n",
       "0             1084\n",
       "1              459\n",
       "2              470\n",
       "3              405\n",
       "4              669"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_sba_office = clean_ppp_data[['sba_office_code']].drop_duplicates()\n",
    "dim_sba_office = dim_sba_office.reset_index(drop=True)\n",
    "dim_sba_office.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_id</th>\n",
       "      <th>term_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   term_id  term_month\n",
       "0        1           0\n",
       "1        2           1\n",
       "2        3           2\n",
       "3        4           3\n",
       "4        5           4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_term = clean_ppp_data[['term_month']].drop_duplicates()\n",
    "dim_term = dim_term.sort_values(by='term_month')\n",
    "dim_term[\"term_id\"] = range(1, len(dim_term) + 1)\n",
    "dim_term = dim_term[['term_id', 'term_month']]\n",
    "dim_term = dim_term.reset_index(drop=True)\n",
    "\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_term[['term_month', 'term_id']], on='term_month', how='left', suffixes=('', '_dim_term'))\n",
    "\n",
    "dim_term.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_age_id</th>\n",
       "      <th>business_age_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Existing or more than 2 years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>New Business or 2 years or less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Change of Ownership</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Startup, Loan Funds will Open Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business_age_id                business_age_description\n",
       "0                1       Existing or more than 2 years old\n",
       "1                2         New Business or 2 years or less\n",
       "2                3                     Change of Ownership\n",
       "3                4  Startup, Loan Funds will Open Business"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_business_age = clean_ppp_data[['business_age_description']].drop_duplicates()\n",
    "dim_business_age[\"business_age_id\"] = range(1, len(dim_business_age) + 1)\n",
    "dim_business_age = dim_business_age[['business_age_id', 'business_age_description']]\n",
    "dim_business_age = dim_business_age.reset_index(drop=True)\n",
    "\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_business_age[['business_age_description', 'business_age_id']], on='business_age_description', how='left', suffixes=('', '_dim_business_age'))\n",
    "\n",
    "dim_business_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dim_business_type data into the database...\n",
      "dim_business_type data loaded successfully\n",
      "\n",
      "Loading dim_sba_office data into the database...\n",
      "dim_sba_office data loaded successfully\n",
      "\n",
      "Loading dim_term data into the database...\n",
      "dim_term data loaded successfully\n",
      "\n",
      "Loading dim_business_age data into the database...\n",
      "dim_business_age data loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dim_business_type data into the database...\")\n",
    "#dim_business_type.to_sql('dim_business_type', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_business_type data loaded successfully\\n\")\n",
    "\n",
    "print(\"Loading dim_sba_office data into the database...\")\n",
    "#dim_sba_office.to_sql('dim_sba_office', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_sba_office data loaded successfully\\n\")\n",
    "\n",
    "print(\"Loading dim_term data into the database...\")\n",
    "#dim_term.to_sql('dim_term', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_term data loaded successfully\\n\")\n",
    "\n",
    "print(\"Loading dim_business_age data into the database...\")\n",
    "#dim_business_age.to_sql('dim_business_age', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_business_age data loaded successfully\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>originating_lender_id</th>\n",
       "      <th>originating_lender_location_id</th>\n",
       "      <th>originating_lender</th>\n",
       "      <th>originating_lender_city</th>\n",
       "      <th>originating_lender_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>116975</td>\n",
       "      <td>Northrim Bank</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>89628</td>\n",
       "      <td>National Cooperative Bank, National Association</td>\n",
       "      <td>Hillsboro</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3386</td>\n",
       "      <td>First National Bank Alaska</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>119918</td>\n",
       "      <td>East West Bank</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>194499</td>\n",
       "      <td>CoBank ACB</td>\n",
       "      <td>Greenwood Village</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   originating_lender_id  originating_lender_location_id  \\\n",
       "0                      1                          116975   \n",
       "1                      2                           89628   \n",
       "2                      3                            3386   \n",
       "3                      4                          119918   \n",
       "4                      5                          194499   \n",
       "\n",
       "                                originating_lender originating_lender_city  \\\n",
       "0                                    Northrim Bank               Anchorage   \n",
       "1  National Cooperative Bank, National Association               Hillsboro   \n",
       "2                       First National Bank Alaska               Anchorage   \n",
       "3                                   East West Bank                Pasadena   \n",
       "4                                       CoBank ACB       Greenwood Village   \n",
       "\n",
       "  originating_lender_state  \n",
       "0                       AK  \n",
       "1                       OH  \n",
       "2                       AK  \n",
       "3                       CA  \n",
       "4                       CO  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_originating_lender = clean_ppp_data[['originating_lender_location_id', 'originating_lender', 'originating_lender_city', 'originating_lender_state']].drop_duplicates()\n",
    "dim_originating_lender[\"originating_lender_id\"] = range(1, len(dim_originating_lender) + 1)\n",
    "# Change column order\n",
    "dim_originating_lender = dim_originating_lender[['originating_lender_id', 'originating_lender_location_id', 'originating_lender', 'originating_lender_city', 'originating_lender_state']]\n",
    "# Reset the index\n",
    "dim_originating_lender = dim_originating_lender.reset_index(drop=True)\n",
    "\n",
    "# Merge the clean_ppp_data with the dim_originating_lender to get the originating_lender_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_originating_lender[['originating_lender_location_id', 'originating_lender_id']], on='originating_lender_location_id', how='left', suffixes=('', '_dim_originating_lender'))\n",
    "\n",
    "dim_originating_lender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borrower_id</th>\n",
       "      <th>borrower_name</th>\n",
       "      <th>borrower_address</th>\n",
       "      <th>borrower_city</th>\n",
       "      <th>borrower_state</th>\n",
       "      <th>borrower_zip</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>veteran</th>\n",
       "      <th>franchise_name</th>\n",
       "      <th>nonprofit</th>\n",
       "      <th>jobs_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>KAKIVIK ASSET MANAGEMENT, LLC</td>\n",
       "      <td>5015 Business Park Blvd</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>99503-7146</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ARCTIC SLOPE NATIVE ASSOCIATION, LTD.</td>\n",
       "      <td>7000 Uula St</td>\n",
       "      <td>Barrow</td>\n",
       "      <td>AK</td>\n",
       "      <td>99723</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>HOPE COMMUNITY RESOURCES INC.</td>\n",
       "      <td>540 W Intl Airport Rd</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>99518-1105</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SOUTH PENINSULA HOSPITAL INC</td>\n",
       "      <td>4300 Bartlett Street</td>\n",
       "      <td>Homer</td>\n",
       "      <td>AK</td>\n",
       "      <td>99603</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>COPPER RIVER SEAFOODS, INC.</td>\n",
       "      <td>1118 5Th Ave</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>99501-2759</td>\n",
       "      <td>Unanswered</td>\n",
       "      <td>Unknown/NotStated</td>\n",
       "      <td>Male Owned</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   borrower_id                          borrower_name  \\\n",
       "0            1          KAKIVIK ASSET MANAGEMENT, LLC   \n",
       "1            2  ARCTIC SLOPE NATIVE ASSOCIATION, LTD.   \n",
       "2            3          HOPE COMMUNITY RESOURCES INC.   \n",
       "3            4           SOUTH PENINSULA HOSPITAL INC   \n",
       "4            5            COPPER RIVER SEAFOODS, INC.   \n",
       "\n",
       "          borrower_address borrower_city borrower_state borrower_zip  \\\n",
       "0  5015 Business Park Blvd     Anchorage             AK   99503-7146   \n",
       "1             7000 Uula St        Barrow             AK        99723   \n",
       "2    540 W Intl Airport Rd     Anchorage             AK   99518-1105   \n",
       "3     4300 Bartlett Street         Homer             AK        99603   \n",
       "4             1118 5Th Ave     Anchorage             AK   99501-2759   \n",
       "\n",
       "         race          ethnicity      gender  veteran franchise_name  \\\n",
       "0  Unanswered  Unknown/NotStated  Unanswered    False           <NA>   \n",
       "1  Unanswered  Unknown/NotStated  Unanswered    False           <NA>   \n",
       "2  Unanswered  Unknown/NotStated  Unanswered    False           <NA>   \n",
       "3  Unanswered  Unknown/NotStated  Unanswered    False           <NA>   \n",
       "4  Unanswered  Unknown/NotStated  Male Owned     True           <NA>   \n",
       "\n",
       "   nonprofit  jobs_reported  \n",
       "0      False            385  \n",
       "1       True            295  \n",
       "2       True            500  \n",
       "3      False            439  \n",
       "4      False            303  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_borrower = clean_ppp_data[['borrower_name', 'borrower_address', 'borrower_city', 'borrower_state', 'borrower_zip', 'race', 'ethnicity', 'gender', 'veteran', 'franchise_name', 'nonprofit', 'jobs_reported']].drop_duplicates()\n",
    "dim_borrower[\"borrower_id\"] = range(1, len(dim_borrower) + 1)\n",
    "# Change the column order\n",
    "dim_borrower = dim_borrower[['borrower_id', 'borrower_name', 'borrower_address', 'borrower_city','borrower_state', 'borrower_zip', 'race', 'ethnicity', 'gender', 'veteran', 'franchise_name', 'nonprofit', 'jobs_reported']]\n",
    "\n",
    "# Reset the index\n",
    "dim_borrower = dim_borrower.reset_index(drop=True)\n",
    "\n",
    "# Merge the clean_ppp_data with the dim_borrower to get the borrower_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_borrower[['borrower_name', 'borrower_address', 'borrower_city', 'borrower_state', 'borrower_zip', 'borrower_id']], on=['borrower_name', 'borrower_address', 'borrower_city', 'borrower_state', 'borrower_zip'], how='left', suffixes=('', '_dim_borrower'))\n",
    "dim_borrower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>servicing_lender_id</th>\n",
       "      <th>servicing_lender_location_id</th>\n",
       "      <th>servicing_lender_name</th>\n",
       "      <th>servicing_lender_address</th>\n",
       "      <th>servicing_lender_city</th>\n",
       "      <th>servicing_lender_state</th>\n",
       "      <th>servicing_lender_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>116975</td>\n",
       "      <td>Northrim Bank</td>\n",
       "      <td>3111 'C' St</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>99503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>89628</td>\n",
       "      <td>National Cooperative Bank, National Association</td>\n",
       "      <td>139 S High St</td>\n",
       "      <td>Hillsboro</td>\n",
       "      <td>OH</td>\n",
       "      <td>45133-1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3386</td>\n",
       "      <td>First National Bank Alaska</td>\n",
       "      <td>101 W 36th Ave</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>AK</td>\n",
       "      <td>99503-5904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>119918</td>\n",
       "      <td>East West Bank</td>\n",
       "      <td>135 N Los Robles Ave, 7th Fl</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>CA</td>\n",
       "      <td>91101-4525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>194499</td>\n",
       "      <td>CoBank ACB</td>\n",
       "      <td>6340 S Fiddlers Green Cir #1908</td>\n",
       "      <td>Greenwood Village</td>\n",
       "      <td>CO</td>\n",
       "      <td>80111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   servicing_lender_id  servicing_lender_location_id  \\\n",
       "0                    1                        116975   \n",
       "1                    2                         89628   \n",
       "2                    3                          3386   \n",
       "3                    4                        119918   \n",
       "4                    5                        194499   \n",
       "\n",
       "                             servicing_lender_name  \\\n",
       "0                                    Northrim Bank   \n",
       "1  National Cooperative Bank, National Association   \n",
       "2                       First National Bank Alaska   \n",
       "3                                   East West Bank   \n",
       "4                                       CoBank ACB   \n",
       "\n",
       "          servicing_lender_address servicing_lender_city  \\\n",
       "0                      3111 'C' St             Anchorage   \n",
       "1                    139 S High St             Hillsboro   \n",
       "2                   101 W 36th Ave             Anchorage   \n",
       "3     135 N Los Robles Ave, 7th Fl              Pasadena   \n",
       "4  6340 S Fiddlers Green Cir #1908     Greenwood Village   \n",
       "\n",
       "  servicing_lender_state servicing_lender_zip  \n",
       "0                     AK                99503  \n",
       "1                     OH           45133-1442  \n",
       "2                     AK           99503-5904  \n",
       "3                     CA           91101-4525  \n",
       "4                     CO                80111  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_servicing_lender = clean_ppp_data[['servicing_lender_location_id', 'servicing_lender_name', 'servicing_lender_address', 'servicing_lender_city', 'servicing_lender_state', 'servicing_lender_zip']].drop_duplicates()\n",
    "dim_servicing_lender[\"servicing_lender_id\"] = range(1, len(dim_servicing_lender) + 1)\n",
    "\n",
    "# Reset the index\n",
    "dim_servicing_lender = dim_servicing_lender.reset_index(drop=True)\n",
    "\n",
    "# Change the column order\n",
    "dim_servicing_lender = dim_servicing_lender[['servicing_lender_id', 'servicing_lender_location_id', 'servicing_lender_name', 'servicing_lender_address', 'servicing_lender_city', 'servicing_lender_state', 'servicing_lender_zip']]\n",
    "\n",
    "# Merge the clean_ppp_data with the dim_servicing_lender to get the servicing_lender_id\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_servicing_lender[['servicing_lender_location_id', 'servicing_lender_id']], on='servicing_lender_location_id', how='left', suffixes=('', '_dim_servicing_lender'))\n",
    "dim_servicing_lender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the clean_ppp_data, create the GEONAME column using the project_state and project_county_name\n",
    "# Make project_state and project_county_name as string\n",
    "clean_ppp_data['project_state'] = clean_ppp_data['project_state'].astype(str)\n",
    "clean_ppp_data['project_county_name'] = clean_ppp_data['project_county_name'].astype(str)\n",
    "clean_ppp_data['geo_name'] = clean_ppp_data['project_county_name'] + ', ' + clean_ppp_data['project_state']\n",
    "\n",
    "# Merge the clean_ppp_data with the dim_geography to get the geofips\n",
    "clean_ppp_data = clean_ppp_data.merge(dim_geography[['geo_name', 'geofips']], on='geo_name', how='left', suffixes=('', '_dim_geography'))\n",
    "# Delete the records that have no geofips in the clean_ppp_data\n",
    "clean_ppp_data = clean_ppp_data.dropna(subset=['geofips'])\n",
    "\n",
    "# Set the data types of the columns\n",
    "clean_ppp_data['geofips'] = clean_ppp_data['geofips'].astype(int)\n",
    "clean_ppp_data['project_state'] = clean_ppp_data['project_state'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "clean_ppp_data['project_county_name'] = clean_ppp_data['project_county_name'].astype(pd.StringDtype(\"pyarrow\"))\n",
    "clean_ppp_data['geo_name'] = clean_ppp_data['geo_name'].astype(pd.StringDtype(\"pyarrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts_ppp_id</th>\n",
       "      <th>loan_number</th>\n",
       "      <th>naics_code</th>\n",
       "      <th>geofips</th>\n",
       "      <th>date_approved_id</th>\n",
       "      <th>loan_status_date_id</th>\n",
       "      <th>forgiveness_date_id</th>\n",
       "      <th>borrower_id</th>\n",
       "      <th>originating_lender_id</th>\n",
       "      <th>servicing_lender_id</th>\n",
       "      <th>...</th>\n",
       "      <th>loan_status_id</th>\n",
       "      <th>processing_method_id</th>\n",
       "      <th>sba_office_code</th>\n",
       "      <th>business_age_id</th>\n",
       "      <th>business_type_id</th>\n",
       "      <th>sba_guaranty_percentage</th>\n",
       "      <th>initial_approval_amount</th>\n",
       "      <th>current_approval_amount</th>\n",
       "      <th>undisbursed_amount</th>\n",
       "      <th>forgiveness_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9621942</th>\n",
       "      <td>9922510</td>\n",
       "      <td>9680978809</td>\n",
       "      <td>621399</td>\n",
       "      <td>41029</td>\n",
       "      <td>2021042300</td>\n",
       "      <td>2021091600</td>\n",
       "      <td>2021082500</td>\n",
       "      <td>9386640</td>\n",
       "      <td>1225</td>\n",
       "      <td>1088</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10867.9</td>\n",
       "      <td>10867.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10903.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621943</th>\n",
       "      <td>9922511</td>\n",
       "      <td>9108608900</td>\n",
       "      <td>114111</td>\n",
       "      <td>41007</td>\n",
       "      <td>2021051200</td>\n",
       "      <td>2022011500</td>\n",
       "      <td>2021122800</td>\n",
       "      <td>9386641</td>\n",
       "      <td>1714</td>\n",
       "      <td>1572</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10867.7</td>\n",
       "      <td>10867.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10934.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621944</th>\n",
       "      <td>9922512</td>\n",
       "      <td>4327788404</td>\n",
       "      <td>111140</td>\n",
       "      <td>41021</td>\n",
       "      <td>2021020600</td>\n",
       "      <td>2021071300</td>\n",
       "      <td>2021062500</td>\n",
       "      <td>9386642</td>\n",
       "      <td>756</td>\n",
       "      <td>705</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10867.0</td>\n",
       "      <td>10867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10905.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621945</th>\n",
       "      <td>9922513</td>\n",
       "      <td>5314208607</td>\n",
       "      <td>713990</td>\n",
       "      <td>41007</td>\n",
       "      <td>2021032000</td>\n",
       "      <td>2021081100</td>\n",
       "      <td>2021071900</td>\n",
       "      <td>9386643</td>\n",
       "      <td>4418</td>\n",
       "      <td>4033</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10867.0</td>\n",
       "      <td>10867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10901.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621946</th>\n",
       "      <td>9922514</td>\n",
       "      <td>1686668706</td>\n",
       "      <td>541110</td>\n",
       "      <td>41051</td>\n",
       "      <td>2021032700</td>\n",
       "      <td>2021041300</td>\n",
       "      <td>2022042700</td>\n",
       "      <td>9386644</td>\n",
       "      <td>390</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1086</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10865.0</td>\n",
       "      <td>10865.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10980.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         facts_ppp_id  loan_number  naics_code  geofips  date_approved_id  \\\n",
       "9621942       9922510   9680978809      621399    41029        2021042300   \n",
       "9621943       9922511   9108608900      114111    41007        2021051200   \n",
       "9621944       9922512   4327788404      111140    41021        2021020600   \n",
       "9621945       9922513   5314208607      713990    41007        2021032000   \n",
       "9621946       9922514   1686668706      541110    41051        2021032700   \n",
       "\n",
       "         loan_status_date_id  forgiveness_date_id  borrower_id  \\\n",
       "9621942           2021091600           2021082500      9386640   \n",
       "9621943           2022011500           2021122800      9386641   \n",
       "9621944           2021071300           2021062500      9386642   \n",
       "9621945           2021081100           2021071900      9386643   \n",
       "9621946           2021041300           2022042700      9386644   \n",
       "\n",
       "         originating_lender_id  servicing_lender_id  ...  loan_status_id  \\\n",
       "9621942                   1225                 1088  ...               1   \n",
       "9621943                   1714                 1572  ...               1   \n",
       "9621944                    756                  705  ...               1   \n",
       "9621945                   4418                 4033  ...               1   \n",
       "9621946                    390                   56  ...               1   \n",
       "\n",
       "         processing_method_id  sba_office_code  business_age_id  \\\n",
       "9621942                     2             1086                1   \n",
       "9621943                     2             1086                1   \n",
       "9621944                     1             1086                1   \n",
       "9621945                     1             1086                1   \n",
       "9621946                     2             1086                1   \n",
       "\n",
       "         business_type_id  sba_guaranty_percentage  initial_approval_amount  \\\n",
       "9621942                 9                    100.0                  10867.9   \n",
       "9621943                 9                    100.0                  10867.7   \n",
       "9621944                 9                    100.0                  10867.0   \n",
       "9621945                 9                    100.0                  10867.0   \n",
       "9621946                 6                    100.0                  10865.0   \n",
       "\n",
       "         current_approval_amount  undisbursed_amount  forgiveness_amount  \n",
       "9621942                  10867.9                 0.0            10903.03  \n",
       "9621943                  10867.7                 0.0            10934.39  \n",
       "9621944                  10867.0                 0.0            10905.11  \n",
       "9621945                  10867.0                 0.0            10901.54  \n",
       "9621946                  10865.0                 0.0            10980.94  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facts_ppp = clean_ppp_data[['facts_ppp_id', 'loan_number', 'naics_code', 'geofips', 'date_approved_id', 'loan_status_date_id', 'forgiveness_date_id', 'borrower_id', 'originating_lender_id', 'servicing_lender_id', 'term_id', 'loan_status_id', 'processing_method_id', 'sba_office_code', 'business_age_id', 'business_type_id', 'sba_guaranty_percentage', 'initial_approval_amount', 'current_approval_amount', 'undisbursed_amount', 'forgiveness_amount']]\n",
    "facts_ppp = facts_ppp.reset_index(drop=True)\n",
    "facts_ppp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dim_originating_lender data into the database...\n",
      "dim_originating_lender data loaded successfully\n",
      "\n",
      "Loading dim_borrower data into the database...\n",
      "dim_borrower data loaded successfully\n",
      "\n",
      "Loading dim_servicing_lender data into the database...\n",
      "dim_servicing_lender data loaded successfully\n",
      "\n",
      "Saving facts_ppp data to a csv file...\n",
      "facts_ppp data saved successfully\n",
      "\n",
      "Loading fact_ppp data into the database...\n",
      "fact_ppp data loaded successfully\n",
      "\n",
      "ETL process completed successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dim_originating_lender data into the database...\")\n",
    "#dim_originating_lender.to_sql('dim_originating_lender', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_originating_lender data loaded successfully\\n\")\n",
    "\n",
    "print(\"Loading dim_borrower data into the database...\")\n",
    "#dim_borrower.to_sql('dim_borrower', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_borrower data loaded successfully\\n\")\n",
    "\n",
    "print(\"Loading dim_servicing_lender data into the database...\")\n",
    "#dim_servicing_lender.to_sql('dim_servicing_lender', engine, schema=schema, if_exists='append', index=False)\n",
    "print(\"dim_servicing_lender data loaded successfully\\n\")\n",
    "\n",
    "print(\"Loading fact_ppp data into the database...\")\n",
    "#facts_ppp.to_sql('facts_ppp', engine, schema=schema, if_exists='replace', index=False)\n",
    "print(\"fact_ppp data loaded successfully\\n\")\n",
    "\n",
    "print(\"ETL process completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
